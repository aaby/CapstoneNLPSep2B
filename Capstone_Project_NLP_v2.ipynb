{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Capstone_Project_NLP.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"slvWhPAgaYGX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709475344,"user_tz":-330,"elapsed":1516,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Import necessary packages\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split \n","import re\n","from bs4 import BeautifulSoup"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9PdFUC2ajna","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598709478260,"user_tz":-330,"elapsed":1220,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"5052b7db-6d61-4305-8667-da24fd66ca74"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SaVJFkPQas2f","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709480804,"user_tz":-330,"elapsed":1124,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/NLP/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eo5-Q-KGaYGc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709483220,"user_tz":-330,"elapsed":1861,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Read input excel sheet\n","\n","df = pd.read_excel(\"input_data.xlsx\", sheet_name=None)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"CFPZBSNkaYGg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709484627,"user_tz":-330,"elapsed":714,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Get the dataframe from first sheet\n","\n","dfn = df['Sheet1']"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"X7ZLt9FLaYGi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1598709487350,"user_tz":-330,"elapsed":1157,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"17c4f069-ffc6-4121-d68d-4135a3f4eead"},"source":["#Lets see head of the dataframe\n","\n","dfn.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Short description</th>\n","      <th>Description</th>\n","      <th>Caller</th>\n","      <th>Assignment group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>login issue</td>\n","      <td>-verified user details.(employee# &amp; manager na...</td>\n","      <td>spxjnwir pjlcoqds</td>\n","      <td>GRP_0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>outlook</td>\n","      <td>\\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...</td>\n","      <td>hmjdrvpb komuaywn</td>\n","      <td>GRP_0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cant log in to vpn</td>\n","      <td>\\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...</td>\n","      <td>eylqgodm ybqkwiam</td>\n","      <td>GRP_0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>unable to access hr_tool page</td>\n","      <td>unable to access hr_tool page</td>\n","      <td>xbkucsvz gcpydteq</td>\n","      <td>GRP_0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>skype error</td>\n","      <td>skype error</td>\n","      <td>owlgqjme qhcozdfx</td>\n","      <td>GRP_0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Short description  ... Assignment group\n","0                    login issue  ...            GRP_0\n","1                        outlook  ...            GRP_0\n","2             cant log in to vpn  ...            GRP_0\n","3  unable to access hr_tool page  ...            GRP_0\n","4                   skype error   ...            GRP_0\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"PCP0o4iAaYGn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598705238914,"user_tz":-330,"elapsed":2010,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"ffac8535-062a-43e0-8f43-b817ecba0927"},"source":["#Shape of the dataframe\n","\n","dfn.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8500, 4)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"S_-Ka_LtaYGq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1598705242906,"user_tz":-330,"elapsed":1169,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"d1f8e3de-f2fa-4054-907f-b568a5dd5822"},"source":["#Check data types\n","\n","dfn.dtypes"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Short description    object\n","Description          object\n","Caller               object\n","Assignment group     object\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"7xCha5KhaYGt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1598685848326,"user_tz":-330,"elapsed":1628,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"4474ce65-4999-45a7-87ae-e3ac70acd0d0"},"source":["#Check for blanks\n","\n","dfn.isna().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Short description    8\n","Description          1\n","Caller               0\n","Assignment group     0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"6kKROJ-eaYGx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"status":"ok","timestamp":1598685850430,"user_tz":-330,"elapsed":784,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"6ea30254-9ffb-49b2-b42f-1a6cfb3c9704"},"source":["#We are more interested in Description column as it clearly looks like superset of short description\n","#So lets see that row with blank value for Description\n","\n","dfn[dfn['Description'].isna()]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Short description</th>\n","      <th>Description</th>\n","      <th>Caller</th>\n","      <th>Assignment group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4395</th>\n","      <td>i am locked out of skype</td>\n","      <td>NaN</td>\n","      <td>viyglzfo ajtfzpkb</td>\n","      <td>GRP_0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             Short description Description             Caller Assignment group\n","4395  i am locked out of skype         NaN  viyglzfo ajtfzpkb            GRP_0"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"zj4XnmAzaYG0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709491887,"user_tz":-330,"elapsed":1229,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Lets fill the description value above with what we have for short description\n","\n","dfn.iloc[4395, dfn.columns.get_loc('Description')] = dfn.iloc[4395, dfn.columns.get_loc('Short description')]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"749BBuG_aYG5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1598705254744,"user_tz":-330,"elapsed":1098,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"8aa4caac-2847-4781-bab2-853d8c4a2e78"},"source":["#Lets check for nulls\n","\n","dfn.isnull().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Short description    8\n","Description          0\n","Caller               0\n","Assignment group     0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"zWd8LRo9aYHA","colab_type":"text"},"source":["We will be using Description column data for training, so we can ignore Short description and Caller"]},{"cell_type":"code","metadata":{"id":"AP5oebIQaYHA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709494983,"user_tz":-330,"elapsed":1223,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["dfn = dfn.drop(['Short description'], axis=1)\n","dfn = dfn.drop(['Caller'], axis=1)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"AwycGiN8aYHK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709497629,"user_tz":-330,"elapsed":1663,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#We noticed there are so many unwanted sequences in Description column\n","#Lets get rid of those\n","\n","dfn[\"Description\"] = dfn[\"Description\"].astype(str) \n","dfn = dfn.replace('\\r\\n','', regex=True)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rl3goyZPaYHN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709500228,"user_tz":-330,"elapsed":1741,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Remove Date and time from description\n","\n","dfn[\"Description\"] = dfn[\"Description\"].replace('\\d{2}/\\d{2}/\\d{4} \\d{2}:\\d{2}:\\d{2}','', regex=True)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqoyWxjLNgmA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709503386,"user_tz":-330,"elapsed":2629,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Remove html characters if any\n","\n","def strip_html_tags(text):\n","    \"\"\"remove html tags from text\"\"\"\n","    soup = BeautifulSoup(text, \"html.parser\")\n","    stripped_text = soup.get_text(separator=\" \")\n","    return stripped_text\n","\n","dfn['Description'] = dfn['Description'].apply(lambda x: strip_html_tags(x))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"YF9la9q5Pato","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1598705276051,"user_tz":-330,"elapsed":4930,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"bda5960d-87e1-43ab-92b5-bcd177d3dc05"},"source":["pip install unidecode"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n","\r\u001b[K     |█▍                              | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 6.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 6.9MB/s \n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q7zbaZOpOuSo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709506780,"user_tz":-330,"elapsed":1677,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Remove Accented Characters if any\n","import unidecode\n","\n","def remove_accented_chars(text):\n","    \"\"\"remove accented characters from text, e.g. café\"\"\"\n","    text = unidecode.unidecode(text)\n","    return text\n","\n","dfn['Description'] = dfn['Description'].apply(lambda x: remove_accented_chars(x))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0ly9XcDPliw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"status":"ok","timestamp":1598705288492,"user_tz":-330,"elapsed":7702,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"71e3c803-77b5-45f4-ea49-7326b53c27ac"},"source":["pip install -U nltk"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting nltk\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n","\r\u001b[K     |▎                               | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 6.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 6.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122kB 7.0MB/s eta 0:00:01\r\u001b[K     |███                             | 133kB 7.0MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143kB 7.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153kB 7.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163kB 7.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 184kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 194kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 204kB 7.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 215kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 225kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 266kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 307kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 317kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 348kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 358kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 368kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 378kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 389kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 399kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 409kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 419kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 430kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 440kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 460kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 471kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 481kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 501kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 512kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 522kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 532kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 542kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 552kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 563kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 573kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 583kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 593kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 604kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 614kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 624kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 634kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 645kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 655kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 665kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 686kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 696kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 706kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 727kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 737kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 747kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 757kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 768kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 778kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 788kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 798kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 808kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 819kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 829kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 839kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 849kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 860kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 870kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 880kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 890kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 901kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 911kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 921kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 931kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 942kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 952kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 962kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 972kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 983kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 993kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.0MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1MB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.2MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3MB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3MB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3MB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3MB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.3MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4MB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4MB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4MB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 7.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.16.0)\n","Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.41.1)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434680 sha256=a56dcade28a9111618c6e5e72db10dfca2c8d3257d6f7c50102d1b330d5edd7e\n","  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n","Successfully built nltk\n","Installing collected packages: nltk\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed nltk-3.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eeVjXWmkWx9I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598709513258,"user_tz":-330,"elapsed":4650,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"506b49ab-bffe-4041-ff7a-d31b536fa2d7"},"source":["#Filter out punctuations\n","\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","\n","def filter_punctuations(text):\n","    tokens = word_tokenize(text)\n","    # remove all tokens that are not alphabetic\n","    words = [word for word in tokens if word.isalpha()]\n","    return ' '.join(words)\n","\n","dfn['Description'] = dfn['Description'].apply(lambda x: filter_punctuations(x))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sb1Bz84SafwO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709515133,"user_tz":-330,"elapsed":1107,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Lowercase the description\n","\n","dfn['Description'] = dfn['Description'].apply(lambda x: x.lower())"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8SpyCFmaulB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709517478,"user_tz":-330,"elapsed":1221,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Remove digits and word containing digits\n","\n","dfn['Description'] = dfn['Description'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"oybnbFUOMnzh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709521421,"user_tz":-330,"elapsed":1196,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Expand Contractions\n","\n","# Dictionary of English Contractions\n","contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\n","                     \"can't\": \"cannot\",\"can't've\": \"cannot have\",\n","                     \"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\n","                     \"couldn't've\": \"could not have\", \"didn't\": \"did not\",\"doesn't\": \"does not\",\n","                     \"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n","                     \"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\n","                     \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\",\n","                     \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\n","                     \"I'd\": \"I would\", \"I'd've\": \"I would have\",\"I'll\": \"I will\",\n","                     \"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\", \"isn't\": \"is not\",\n","                     \"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\n","                     \"it'll've\": \"it will have\", \"let's\": \"let us\",\"ma'am\": \"madam\",\n","                     \"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\", \n","                     \"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\n","                     \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n","                     \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n","                     \"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n","                     \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\n","                     \"she'll\": \"she will\", \"she'll've\": \"she will have\",\"should've\": \"should have\",\n","                     \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\"so've\": \"so have\",\n","                     \"that'd\": \"that would\",\"that'd've\": \"that would have\", \"there'd\": \"there would\",\n","                     \"there'd've\": \"there would have\", \"they'd\": \"they would\",\n","                     \"they'd've\": \"they would have\",\"they'll\": \"they will\",\n","                     \"they'll've\": \"they will have\", \"they're\": \"they are\",\"they've\": \"they have\",\n","                     \"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n","                     \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n","                     \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\",\"what'll\": \"what will\",\n","                     \"what'll've\": \"what will have\",\"what're\": \"what are\", \"what've\": \"what have\",\n","                     \"when've\": \"when have\",\"where'd\": \"where did\", \"where've\": \"where have\",\n","                     \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n","                     \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\n","                     \"won't've\": \"will not have\", \"would've\": \"would have\",\"wouldn't\": \"would not\",\n","                     \"wouldn't've\": \"would not have\",\"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n","                     \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n","                     \"y'all've\": \"you all have\", \"you'd\": \"you would\",\"you'd've\": \"you would have\",\n","                     \"you'll\": \"you will\",\"you'll've\": \"you will have\", \"you're\": \"you are\",\n","                     \"you've\": \"you have\"}\n","\n","# Regular expression for finding contractions\n","contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n","\n","# Function for expanding contractions\n","def expand_contractions(text,contractions_dict=contractions_dict):\n","  def replace(match):\n","    return contractions_dict[match.group(0)]\n","  return contractions_re.sub(replace, text)\n","\n","dfn['Description'] = dfn['Description'].apply(lambda x:expand_contractions(x))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3rq_V96TqL8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598709527748,"user_tz":-330,"elapsed":4378,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"749c4eae-1292-40f2-a301-5edbab099d7e"},"source":["#Filter out stopwords\n","\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","def filter_stopwords(text):\n","    tokens = word_tokenize(text)\n","    # remove all tokens that are stopwords\n","    stop_words = set(stopwords.words('english'))\n","    words = [w for w in tokens if not w in stop_words]\n","    return ' '.join(words)\n","\n","dfn['Description'] = dfn['Description'].apply(lambda x: filter_stopwords(x))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JIxQEWOCZT77","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709557524,"user_tz":-330,"elapsed":28338,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Lemmatization\n","\n","import spacy\n","\n","# Loading model\n","nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n","\n","dfn['lemmatized'] = dfn['Description'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x))]))\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEeO_6UfLDdY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598709561276,"user_tz":-330,"elapsed":1204,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"e6938cc3-2bbc-4617-969d-6a5b76e1962e"},"source":["#Check and remove empty rows after lemmatization\n","\n","print(dfn.shape)\n","dfn = dfn[dfn['lemmatized'] != '']\n","print(dfn.shape)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["(8500, 3)\n","(8430, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XpUOgd_2f_D4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":677},"executionInfo":{"status":"ok","timestamp":1598709564933,"user_tz":-330,"elapsed":1144,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"01a7daa2-c50c-464d-936b-e4811c78d3c2"},"source":["#Lets group the lemmatized descriptions based on assignment groups\n","\n","df_grouped = dfn[['Assignment group','lemmatized']].groupby(by='Assignment group').agg(lambda x:' '.join(x))\n","df_grouped.head(20)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lemmatized</th>\n","    </tr>\n","    <tr>\n","      <th>Assignment group</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>GRP_0</th>\n","      <td>user details employee manager name user name a...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_1</th>\n","      <td>event critical value mountpoint threshold toda...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_10</th>\n","      <td>receive fail receive fail receive fail receive...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_11</th>\n","      <td>hello service nee monitor manufacture drawing ...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_12</th>\n","      <td>c label server space consume space available g...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_13</th>\n","      <td>receive fail receive two customer account get ...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_14</th>\n","      <td>intermittent service configair server require ...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_15</th>\n","      <td>hi channel partner email address djhadkudhd re...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_16</th>\n","      <td>receive cid bwfhtumx japznrvb regional control...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_17</th>\n","      <td>employee get error user authentication fail tr...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_18</th>\n","      <td>receive hello team could please generate deliv...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_19</th>\n","      <td>unable take print xdvwitpm zscxqdhoalaramdntya...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_2</th>\n","      <td>try change password acc attach work office vac...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_20</th>\n","      <td>datum correctly pull employee attendee interfa...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_21</th>\n","      <td>need approve new product request internal user...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_22</th>\n","      <td>assign crm license nyrjkctu use profile like q...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_23</th>\n","      <td>unable see current course ethic user -PRON- wo...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_24</th>\n","      <td>support fa r ohxdwngl hallo es ist erneut pass...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_25</th>\n","      <td>crashes confirmation delete able remove scrap ...</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_26</th>\n","      <td>receive message tell email mention send usa us...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                         lemmatized\n","Assignment group                                                   \n","GRP_0             user details employee manager name user name a...\n","GRP_1             event critical value mountpoint threshold toda...\n","GRP_10            receive fail receive fail receive fail receive...\n","GRP_11            hello service nee monitor manufacture drawing ...\n","GRP_12            c label server space consume space available g...\n","GRP_13            receive fail receive two customer account get ...\n","GRP_14            intermittent service configair server require ...\n","GRP_15            hi channel partner email address djhadkudhd re...\n","GRP_16            receive cid bwfhtumx japznrvb regional control...\n","GRP_17            employee get error user authentication fail tr...\n","GRP_18            receive hello team could please generate deliv...\n","GRP_19            unable take print xdvwitpm zscxqdhoalaramdntya...\n","GRP_2             try change password acc attach work office vac...\n","GRP_20            datum correctly pull employee attendee interfa...\n","GRP_21            need approve new product request internal user...\n","GRP_22            assign crm license nyrjkctu use profile like q...\n","GRP_23            unable see current course ethic user -PRON- wo...\n","GRP_24            support fa r ohxdwngl hallo es ist erneut pass...\n","GRP_25            crashes confirmation delete able remove scrap ...\n","GRP_26            receive message tell email mention send usa us..."]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"CEGpnlGqdO3r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"status":"ok","timestamp":1598709568370,"user_tz":-330,"elapsed":1186,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"8a4021e2-6735-4c11-f9c1-e085e02c3824"},"source":["# Lets create Document Term Matrix\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","cv = CountVectorizer(analyzer='word')\n","data = cv.fit_transform(df_grouped['lemmatized'])\n","\n","df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names())\n","df_dtm.index = df_grouped.index\n","df_dtm.head(10)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aa</th>\n","      <th>aaa</th>\n","      <th>aaeur</th>\n","      <th>aao</th>\n","      <th>aaymanncustom</th>\n","      <th>ab</th>\n","      <th>abandon</th>\n","      <th>abap</th>\n","      <th>abarbeiten</th>\n","      <th>abc</th>\n","      <th>abca</th>\n","      <th>abcdegy</th>\n","      <th>abcdri</th>\n","      <th>abd</th>\n","      <th>abdhtyu</th>\n","      <th>abend</th>\n","      <th>abende</th>\n","      <th>abended</th>\n","      <th>aber</th>\n","      <th>abertura</th>\n","      <th>abfragetimeout</th>\n","      <th>abgebildet</th>\n","      <th>abgebrochen</th>\n","      <th>abgelaufen</th>\n","      <th>abgeschlossen</th>\n","      <th>abgesprochen</th>\n","      <th>abgrtyreu</th>\n","      <th>abhanden</th>\n","      <th>abhandengekommen</th>\n","      <th>abhay</th>\n","      <th>abhilfe</th>\n","      <th>abholen</th>\n","      <th>abholung</th>\n","      <th>ability</th>\n","      <th>abl</th>\n","      <th>able</th>\n","      <th>abmelden</th>\n","      <th>abode</th>\n","      <th>abort</th>\n","      <th>abovementione</th>\n","      <th>...</th>\n","      <th>zugang</th>\n","      <th>zugordnet</th>\n","      <th>zugriff</th>\n","      <th>zugriffe</th>\n","      <th>zugriffs</th>\n","      <th>zugriffsrechte</th>\n","      <th>zuhause</th>\n","      <th>zuhoylts</th>\n","      <th>zukommen</th>\n","      <th>zulassen</th>\n","      <th>zum</th>\n","      <th>zumindest</th>\n","      <th>zuothryrt</th>\n","      <th>zur</th>\n","      <th>zura</th>\n","      <th>zurtxjbd</th>\n","      <th>zurzeit</th>\n","      <th>zusammen</th>\n","      <th>zuschaltung</th>\n","      <th>zusta</th>\n","      <th>zuteillisten</th>\n","      <th>zuvjqgwa</th>\n","      <th>zuvor</th>\n","      <th>zuyimtsf</th>\n","      <th>zvjxuahe</th>\n","      <th>zvmesjpt</th>\n","      <th>zvnxlobq</th>\n","      <th>zvnxlobqdirecteur</th>\n","      <th>zvygmnco</th>\n","      <th>zwar</th>\n","      <th>zwei</th>\n","      <th>zweites</th>\n","      <th>zwip</th>\n","      <th>zwischen</th>\n","      <th>zwrypjqv</th>\n","      <th>zwutmehy</th>\n","      <th>zwwirep</th>\n","      <th>zxdtskpw</th>\n","      <th>zyjfpgtk</th>\n","      <th>zz</th>\n","    </tr>\n","    <tr>\n","      <th>Assignment group</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>GRP_0</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>266</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_10</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_11</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_12</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_13</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_14</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_15</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_16</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>GRP_17</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 10829 columns</p>\n","</div>"],"text/plain":["                  aa  aaa  aaeur  aao  ...  zwwirep  zxdtskpw  zyjfpgtk  zz\n","Assignment group                       ...                                 \n","GRP_0              0    2      0    0  ...        0         1         0   0\n","GRP_1              0    0      0    0  ...        0         0         0   0\n","GRP_10             0    0      0    0  ...        0         0         0   0\n","GRP_11             0    0      0    0  ...        1         0         0   0\n","GRP_12             0    0      0    0  ...        0         0         0   0\n","GRP_13             0    0      0    0  ...        0         0         0   0\n","GRP_14             0    2      0    0  ...        0         0         0   0\n","GRP_15             0    0      0    0  ...        0         0         0   0\n","GRP_16             0    0      0    0  ...        0         0         0   0\n","GRP_17             0    0      0    0  ...        0         0         0   0\n","\n","[10 rows x 10829 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"qV7o3sfae8VV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1wygz9tP1a4GVxGFcR3DrgucQGT_lbd2C"},"executionInfo":{"status":"ok","timestamp":1598705444314,"user_tz":-330,"elapsed":42784,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"7a8d954f-d295-4b42-e961-92d648c06548"},"source":["# Importing wordcloud for plotting word clouds and textwrap for wrapping longer text\n","from wordcloud import WordCloud\n","from textwrap import wrap\n","\n","# Function for generating word clouds\n","def generate_wordcloud(data,title):\n","  try:\n","    wc = WordCloud(width=400, height=330, max_words=150,colormap=\"Dark2\").generate_from_frequencies(data)\n","    plt.figure(figsize=(10,8))\n","    plt.imshow(wc, interpolation='bilinear')\n","    plt.axis(\"off\")\n","    plt.title('\\n'.join(wrap(title,60)),fontsize=13)\n","    plt.show()\n","  except:\n","    print(\"Error happened\")\n","  \n","# Transposing document term matrix\n","df_dtm = df_dtm.transpose()\n","\n","\n","# Plotting word cloud for each group\n","for index, group in enumerate(df_dtm.columns):\n","    generate_wordcloud(df_dtm[group].sort_values(ascending=False), group)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"2e0W7Wz6b_d7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":892},"executionInfo":{"status":"ok","timestamp":1598547024850,"user_tz":-330,"elapsed":2032,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"a8070ab2-578b-4ed2-ffc8-b55e7b29e853"},"source":["#Lets check how balanced our classification is\n","\n","dfn['Assignment group'].value_counts().plot(kind='bar', figsize=(25,15));"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1800x1080 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"bcEmKNqVn_Jx","colab_type":"text"},"source":["We can see how unbalanced our dataset is. We will try to make use of NLP data augmentation techniques."]},{"cell_type":"code","metadata":{"id":"bDrU_LiGqmQD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598709577741,"user_tz":-330,"elapsed":1822,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"3f6105c7-397d-48b5-f199-c3b5e35f5e74"},"source":["#!/usr/bin/python\n","# -*- coding: utf-8 -*-\n","\n","# Easy data augmentation techniques for text classification\n","\n","import random\n","from random import shuffle\n","random.seed(1)\n","\n","# stop words list\n","\n","stop_words = [\n","    'i',\n","    'me',\n","    'my',\n","    'myself',\n","    'we',\n","    'our',\n","    'ours',\n","    'ourselves',\n","    'you',\n","    'your',\n","    'yours',\n","    'yourself',\n","    'yourselves',\n","    'he',\n","    'him',\n","    'his',\n","    'himself',\n","    'she',\n","    'her',\n","    'hers',\n","    'herself',\n","    'it',\n","    'its',\n","    'itself',\n","    'they',\n","    'them',\n","    'their',\n","    'theirs',\n","    'themselves',\n","    'what',\n","    'which',\n","    'who',\n","    'whom',\n","    'this',\n","    'that',\n","    'these',\n","    'those',\n","    'am',\n","    'is',\n","    'are',\n","    'was',\n","    'were',\n","    'be',\n","    'been',\n","    'being',\n","    'have',\n","    'has',\n","    'had',\n","    'having',\n","    'do',\n","    'does',\n","    'did',\n","    'doing',\n","    'a',\n","    'an',\n","    'the',\n","    'and',\n","    'but',\n","    'if',\n","    'or',\n","    'because',\n","    'as',\n","    'until',\n","    'while',\n","    'of',\n","    'at',\n","    'by',\n","    'for',\n","    'with',\n","    'about',\n","    'against',\n","    'between',\n","    'into',\n","    'through',\n","    'during',\n","    'before',\n","    'after',\n","    'above',\n","    'below',\n","    'to',\n","    'from',\n","    'up',\n","    'down',\n","    'in',\n","    'out',\n","    'on',\n","    'off',\n","    'over',\n","    'under',\n","    'again',\n","    'further',\n","    'then',\n","    'once',\n","    'here',\n","    'there',\n","    'when',\n","    'where',\n","    'why',\n","    'how',\n","    'all',\n","    'any',\n","    'both',\n","    'each',\n","    'few',\n","    'more',\n","    'most',\n","    'other',\n","    'some',\n","    'such',\n","    'no',\n","    'nor',\n","    'not',\n","    'only',\n","    'own',\n","    'same',\n","    'so',\n","    'than',\n","    'too',\n","    'very',\n","    's',\n","    't',\n","    'can',\n","    'will',\n","    'just',\n","    'don',\n","    'should',\n","    'now',\n","    '',\n","    ]\n","\n","# cleaning up text\n","\n","import re\n","\n","\n","def get_only_chars(line):\n","\n","    clean_line = ''\n","\n","    line = line.replace('\\xe2\\x80\\x99', '')\n","    line = line.replace(\"'\", '')\n","    line = line.replace('-', ' ')  # replace hyphens with spaces\n","    line = line.replace('\\t', ' ')\n","    line = line.replace('\\n', ' ')\n","    line = line.lower()\n","\n","    for char in line:\n","        if char in 'qwertyuiopasdfghjklzxcvbnm ':\n","            clean_line += char\n","        else:\n","            clean_line += ' '\n","\n","    clean_line = re.sub(' +', ' ', clean_line)  # delete extra spaces\n","    if len(clean_line) > 0 and clean_line[0] == ' ':\n","        clean_line = clean_line[1:]\n","    return clean_line\n","\n","\n","########################################################################\n","# Synonym replacement\n","# Replace n words in the sentence with synonyms from wordnet\n","########################################################################\n","\n","import nltk\n","nltk.download('wordnet')\n","from nltk.corpus import wordnet\n","\n","\n","def synonym_replacement(words, n):\n","    new_words = words.copy()\n","    random_word_list = list(set([word for word in words if word\n","                            not in stop_words]))\n","    random.shuffle(random_word_list)\n","    num_replaced = 0\n","    for random_word in random_word_list:\n","        synonyms = get_synonyms(random_word)\n","        if len(synonyms) >= 1:\n","            synonym = random.choice(list(synonyms))\n","            new_words = [(synonym if word == random_word else word)\n","                         for word in new_words]\n","\n","            # print(\"replaced\", random_word, \"with\", synonym)\n","\n","            num_replaced += 1\n","        if num_replaced >= n:  # only replace up to n words\n","            break\n","\n","    # this is stupid but we need it, trust me\n","\n","    sentence = ' '.join(new_words)\n","    new_words = sentence.split(' ')\n","\n","    return new_words\n","\n","\n","def get_synonyms(word):\n","    synonyms = set()\n","    for syn in wordnet.synsets(word):\n","        for l in syn.lemmas():\n","            synonym = l.name().replace('_', ' ').replace('-', ' '\n","                    ).lower()\n","            synonym = ''.join([char for char in synonym if char\n","                              in ' qwertyuiopasdfghjklzxcvbnm'])\n","            synonyms.add(synonym)\n","    if word in synonyms:\n","        synonyms.remove(word)\n","    return list(synonyms)\n","\n","\n","########################################################################\n","# Random deletion\n","# Randomly delete words from the sentence with probability p\n","########################################################################\n","\n","def random_deletion(words, p):\n","\n","    # obviously, if there's only one word, don't delete it\n","\n","    if len(words) == 1:\n","        return words\n","\n","    # randomly delete words with probability p\n","\n","    new_words = []\n","    for word in words:\n","        r = random.uniform(0, 1)\n","        if r > p:\n","            new_words.append(word)\n","\n","    # if you end up deleting all words, just return a random word\n","\n","    if len(new_words) == 0:\n","        rand_int = random.randint(0, len(words) - 1)\n","        return [words[rand_int]]\n","\n","    return new_words\n","\n","\n","########################################################################\n","# Random swap\n","# Randomly swap two words in the sentence n times\n","########################################################################\n","\n","def random_swap(words, n):\n","    new_words = words.copy()\n","    for _ in range(n):\n","        new_words = swap_word(new_words)\n","    return new_words\n","\n","\n","def swap_word(new_words):\n","    random_idx_1 = random.randint(0, len(new_words) - 1)\n","    random_idx_2 = random_idx_1\n","    counter = 0\n","    while random_idx_2 == random_idx_1:\n","        random_idx_2 = random.randint(0, len(new_words) - 1)\n","        counter += 1\n","        if counter > 3:\n","            return new_words\n","    (new_words[random_idx_1], new_words[random_idx_2]) = \\\n","        (new_words[random_idx_2], new_words[random_idx_1])\n","    return new_words\n","\n","\n","########################################################################\n","# Random insertion\n","# Randomly insert n words into the sentence\n","########################################################################\n","\n","def random_insertion(words, n):\n","    new_words = words.copy()\n","    for _ in range(n):\n","        add_word(new_words)\n","    return new_words\n","\n","\n","def add_word(new_words):\n","    synonyms = []\n","    counter = 0\n","    while len(synonyms) < 1:\n","        random_word = new_words[random.randint(0, len(new_words) - 1)]\n","        synonyms = get_synonyms(random_word)\n","        counter += 1\n","        if counter >= 10:\n","            return\n","    random_synonym = synonyms[0]\n","    random_idx = random.randint(0, len(new_words) - 1)\n","    new_words.insert(random_idx, random_synonym)\n","\n","\n","########################################################################\n","# main data augmentation function\n","########################################################################\n","\n","def eda(\n","    sentence,\n","    alpha_sr=0.1,\n","    alpha_ri=0.1,\n","    alpha_rs=0.1,\n","    p_rd=0.1,\n","    num_aug=9,\n","    ri=True,\n","    rd=True,\n","    ):\n","\n","    sentence = get_only_chars(sentence)\n","    words = sentence.split(' ')\n","    words = [word for word in words if word is not '']\n","    num_words = len(words)\n","\n","    augmented_sentences = []\n","    num_new_per_technique = int(num_aug / 4) + 1\n","    n_sr = max(1, int(alpha_sr * num_words))\n","    n_ri = max(1, int(alpha_ri * num_words))\n","    n_rs = max(1, int(alpha_rs * num_words))\n","\n","    # sr\n","    for _ in range(num_new_per_technique):\n","        a_words = synonym_replacement(words, n_sr)\n","        augmented_sentences.append(' '.join(a_words))\n","\n","    # ri\n","    if ri:\n","        for _ in range(num_new_per_technique):\n","            a_words = random_insertion(words, n_ri)\n","            augmented_sentences.append(' '.join(a_words))\n","\n","    # rs\n","    for _ in range(num_new_per_technique):\n","        a_words = random_swap(words, n_rs)\n","        augmented_sentences.append(' '.join(a_words))\n","\n","    # rd\n","    if rd:\n","        for _ in range(num_new_per_technique):\n","            a_words = random_deletion(words, p_rd)\n","            augmented_sentences.append(' '.join(a_words))\n","\n","    augmented_sentences = [get_only_chars(sentence) for sentence in\n","                           augmented_sentences]\n","    shuffle(augmented_sentences)\n","\n","    # trim so that we have the desired number of augmented sentences\n","    if num_aug >= 1:\n","        augmented_sentences = augmented_sentences[:num_aug]\n","    else:\n","        keep_prob = num_aug / len(augmented_sentences)\n","        augmented_sentences = [s for s in augmented_sentences\n","                               if random.uniform(0, 1) < keep_prob]\n","\n","    # append the original sentence\n","    augmented_sentences.append(sentence)\n","\n","    return augmented_sentences"],"execution_count":22,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"15eLqcAaSD1a","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709584757,"user_tz":-330,"elapsed":1142,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#We dont need Description column anymore\n","\n","dfn = dfn.drop(['Description'], axis=1)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJQlpTce7J4w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1598709762861,"user_tz":-330,"elapsed":177435,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"6ef1718a-12db-40db-8b9e-2bfe127a01cb"},"source":["#Lets augment text for groups other than GRP_0\n","\n","df_aug = pd.DataFrame(columns=dfn.columns)\n","\n","for index, row in dfn.iterrows():\n","  if row['Assignment group'] != 'GRP_0':\n","      sentences = eda(row['lemmatized'])\n","      for sentence in sentences:\n","        df_aug = df_aug.append({'Assignment group': row['Assignment group'], 'lemmatized': sentence}, ignore_index=True)\n","df_aug.head()"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Assignment group</th>\n","      <th>lemmatized</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GRP_1</td>\n","      <td>mountpoint critical value event threshold</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>GRP_1</td>\n","      <td>consequence critical value mountpoint threshold</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>GRP_1</td>\n","      <td>event critical value mountpoint threshold</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GRP_1</td>\n","      <td>limen event critical value mountpoint threshold</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>GRP_1</td>\n","      <td>event critical value mountpoint threshold</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Assignment group                                       lemmatized\n","0            GRP_1        mountpoint critical value event threshold\n","1            GRP_1  consequence critical value mountpoint threshold\n","2            GRP_1        event critical value mountpoint threshold\n","3            GRP_1  limen event critical value mountpoint threshold\n","4            GRP_1        event critical value mountpoint threshold"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"xrSgDqF_UBQH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709808400,"user_tz":-330,"elapsed":1537,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Append df_aug to parent dataframe dfn\n","\n","dfn = dfn.append(df_aug) "],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"qBPFU4V_UjLQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":892},"executionInfo":{"status":"ok","timestamp":1598709811902,"user_tz":-330,"elapsed":2527,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"91cfc485-731c-43be-cf4f-04f11aa96cb0"},"source":["#Lets check classification plot again\n","\n","dfn['Assignment group'].value_counts().plot(kind='bar', figsize=(25,15));"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1800x1080 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"RdGedmRt3V7v","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709817094,"user_tz":-330,"elapsed":2378,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Separate train and target columns\n","\n","X = dfn.lemmatized\n","y = dfn['Assignment group']"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"fCCCyz8r23nM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709825384,"user_tz":-330,"elapsed":6969,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Split the data into train and test\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ATDReEF_13jH","colab_type":"text"},"source":["# Lets try our \"Naive\" Naive Bayes Classification"]},{"cell_type":"code","metadata":{"id":"CBBc-rH6Uc_A","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709835600,"user_tz":-330,"elapsed":4215,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["groupNames = dfn['Assignment group'].unique()"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2kTtXIA2InZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598709841165,"user_tz":-330,"elapsed":2098,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"bfcd50c3-ccfb-436d-a787-849aa591d31d"},"source":["from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.metrics import accuracy_score\n","\n","nb = Pipeline([('vect', CountVectorizer()),\n","               ('tfidf', TfidfTransformer()),\n","               ('clf', MultinomialNB()),\n","              ])\n","nb.fit(X_train, y_train)\n","\n","from sklearn.metrics import classification_report\n","y_pred = nb.predict(X_test)\n","\n","print('accuracy %s' % accuracy_score(y_pred, y_test))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["accuracy 0.6319509896324222\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UR2UtUmTW8B6","colab_type":"text"},"source":["# Lets try text classification using Keras "]},{"cell_type":"code","metadata":{"id":"4bb1kdxxZJxf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598709847211,"user_tz":-330,"elapsed":1165,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["dfn['AG'] = dfn['Assignment group'].str[4:]\n","lbls = dfn[\"AG\"].values\n","labels = [int(numeric_string) for numeric_string in lbls]"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xjxb3ms6XsWT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598710052431,"user_tz":-330,"elapsed":203113,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"76fc7894-2aa6-46f7-9104-9dd7a76eef6b"},"source":["import numpy as np\n","\n","from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n","from sklearn.metrics import confusion_matrix\n","\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout\n","from keras.preprocessing import text, sequence\n","from keras import utils\n","\n","train_size = int(len(dfn) * .7)\n","train_posts = dfn['lemmatized'][:train_size]\n","train_tags = dfn['AG'][:train_size]\n","\n","test_posts = dfn['lemmatized'][train_size:]\n","test_tags = dfn['AG'][train_size:]\n","\n","max_words = 1000\n","tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n","tokenize.fit_on_texts(train_posts) # only fit on train\n","\n","x_train = tokenize.texts_to_matrix(train_posts)\n","x_test = tokenize.texts_to_matrix(test_posts)\n","\n","encoder = LabelEncoder()\n","encoder.fit(train_tags)\n","y_train = encoder.transform(train_tags)\n","y_test = encoder.transform(test_tags)\n","\n","num_classes = np.max(y_train) + 1\n","y_train = utils.to_categorical(y_train, num_classes)\n","y_test = utils.to_categorical(y_test, num_classes)\n","\n","batch_size = 32\n","epochs = 50\n","\n","# Build the model\n","kmodel = Sequential()\n","kmodel.add(Dense(512, input_shape=(max_words,)))\n","kmodel.add(Activation('relu'))\n","kmodel.add(Dropout(0.5))\n","kmodel.add(Dense(num_classes))\n","kmodel.add(Activation('softmax'))\n","\n","kmodel.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","              \n","history = kmodel.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_split=0.1)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 1.7021 - accuracy: 0.5699 - val_loss: 1.8887 - val_accuracy: 0.4467\n","Epoch 2/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.8385 - accuracy: 0.7594 - val_loss: 1.6700 - val_accuracy: 0.4949\n","Epoch 3/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.6808 - accuracy: 0.7985 - val_loss: 1.4690 - val_accuracy: 0.5318\n","Epoch 4/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.6066 - accuracy: 0.8155 - val_loss: 1.3336 - val_accuracy: 0.5654\n","Epoch 5/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.5577 - accuracy: 0.8272 - val_loss: 1.1874 - val_accuracy: 0.6101\n","Epoch 6/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.5250 - accuracy: 0.8344 - val_loss: 1.0872 - val_accuracy: 0.6500\n","Epoch 7/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4978 - accuracy: 0.8414 - val_loss: 0.9431 - val_accuracy: 0.6745\n","Epoch 8/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4796 - accuracy: 0.8458 - val_loss: 0.9007 - val_accuracy: 0.6933\n","Epoch 9/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4669 - accuracy: 0.8498 - val_loss: 0.8522 - val_accuracy: 0.6933\n","Epoch 10/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4493 - accuracy: 0.8535 - val_loss: 0.8366 - val_accuracy: 0.6998\n","Epoch 11/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4477 - accuracy: 0.8540 - val_loss: 0.8159 - val_accuracy: 0.7038\n","Epoch 12/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4362 - accuracy: 0.8584 - val_loss: 0.7987 - val_accuracy: 0.7181\n","Epoch 13/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4314 - accuracy: 0.8597 - val_loss: 0.7894 - val_accuracy: 0.7181\n","Epoch 14/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4235 - accuracy: 0.8599 - val_loss: 0.8007 - val_accuracy: 0.7270\n","Epoch 15/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4184 - accuracy: 0.8629 - val_loss: 0.8145 - val_accuracy: 0.7219\n","Epoch 16/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4173 - accuracy: 0.8624 - val_loss: 0.7556 - val_accuracy: 0.7302\n","Epoch 17/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4142 - accuracy: 0.8631 - val_loss: 0.7404 - val_accuracy: 0.7294\n","Epoch 18/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4082 - accuracy: 0.8647 - val_loss: 0.7045 - val_accuracy: 0.7299\n","Epoch 19/50\n","1045/1045 [==============================] - 5s 4ms/step - loss: 0.4044 - accuracy: 0.8651 - val_loss: 0.7502 - val_accuracy: 0.7289\n","Epoch 20/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4027 - accuracy: 0.8652 - val_loss: 0.7440 - val_accuracy: 0.7316\n","Epoch 21/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.4013 - accuracy: 0.8672 - val_loss: 0.7542 - val_accuracy: 0.7426\n","Epoch 22/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3993 - accuracy: 0.8661 - val_loss: 0.7313 - val_accuracy: 0.7375\n","Epoch 23/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3970 - accuracy: 0.8668 - val_loss: 0.7264 - val_accuracy: 0.7380\n","Epoch 24/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3947 - accuracy: 0.8681 - val_loss: 0.7456 - val_accuracy: 0.7512\n","Epoch 25/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3927 - accuracy: 0.8676 - val_loss: 0.7088 - val_accuracy: 0.7491\n","Epoch 26/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3926 - accuracy: 0.8694 - val_loss: 0.6915 - val_accuracy: 0.7491\n","Epoch 27/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3935 - accuracy: 0.8683 - val_loss: 0.7166 - val_accuracy: 0.7418\n","Epoch 28/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3909 - accuracy: 0.8686 - val_loss: 0.6887 - val_accuracy: 0.7480\n","Epoch 29/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3870 - accuracy: 0.8694 - val_loss: 0.6933 - val_accuracy: 0.7453\n","Epoch 30/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3862 - accuracy: 0.8696 - val_loss: 0.6943 - val_accuracy: 0.7523\n","Epoch 31/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3884 - accuracy: 0.8695 - val_loss: 0.7355 - val_accuracy: 0.7380\n","Epoch 32/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3873 - accuracy: 0.8698 - val_loss: 0.6753 - val_accuracy: 0.7477\n","Epoch 33/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3891 - accuracy: 0.8709 - val_loss: 0.7108 - val_accuracy: 0.7456\n","Epoch 34/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3853 - accuracy: 0.8712 - val_loss: 0.6829 - val_accuracy: 0.7501\n","Epoch 35/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3857 - accuracy: 0.8714 - val_loss: 0.7455 - val_accuracy: 0.7458\n","Epoch 36/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3830 - accuracy: 0.8707 - val_loss: 0.6917 - val_accuracy: 0.7447\n","Epoch 37/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3828 - accuracy: 0.8712 - val_loss: 0.7165 - val_accuracy: 0.7553\n","Epoch 38/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3778 - accuracy: 0.8718 - val_loss: 0.7040 - val_accuracy: 0.7582\n","Epoch 39/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3784 - accuracy: 0.8719 - val_loss: 0.7071 - val_accuracy: 0.7523\n","Epoch 40/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3812 - accuracy: 0.8705 - val_loss: 0.7243 - val_accuracy: 0.7461\n","Epoch 41/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3805 - accuracy: 0.8712 - val_loss: 0.6865 - val_accuracy: 0.7504\n","Epoch 42/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3824 - accuracy: 0.8721 - val_loss: 0.6775 - val_accuracy: 0.7523\n","Epoch 43/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3756 - accuracy: 0.8709 - val_loss: 0.7203 - val_accuracy: 0.7491\n","Epoch 44/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3819 - accuracy: 0.8720 - val_loss: 0.7442 - val_accuracy: 0.7434\n","Epoch 45/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3824 - accuracy: 0.8708 - val_loss: 0.7027 - val_accuracy: 0.7480\n","Epoch 46/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3755 - accuracy: 0.8722 - val_loss: 0.7229 - val_accuracy: 0.7445\n","Epoch 47/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3775 - accuracy: 0.8724 - val_loss: 0.7179 - val_accuracy: 0.7442\n","Epoch 48/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3766 - accuracy: 0.8716 - val_loss: 0.7222 - val_accuracy: 0.7453\n","Epoch 49/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3754 - accuracy: 0.8732 - val_loss: 0.7742 - val_accuracy: 0.7447\n","Epoch 50/50\n","1045/1045 [==============================] - 4s 4ms/step - loss: 0.3766 - accuracy: 0.8731 - val_loss: 0.7408 - val_accuracy: 0.7579\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YjFA9F3NcWyc","colab_type":"text"},"source":["# We should try Transformers! Lets try Bert"]},{"cell_type":"code","metadata":{"id":"p1rWOzd5cgqd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"status":"ok","timestamp":1598710069926,"user_tz":-330,"elapsed":4052,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"efa325ab-1319-4833-8cbf-2395d4a0cde4"},"source":["pip install transformers"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m4lM1DxtiDvS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":285},"executionInfo":{"status":"ok","timestamp":1598710076332,"user_tz":-330,"elapsed":4958,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"0fe1bae9-70df-4a42-9294-315483f708be"},"source":["import transformers\n","import numpy as np\n","\n","txt = \"bank river\"\n","## bert tokenizer\n","tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","## bert model\n","nlp = transformers.TFBertModel.from_pretrained('bert-base-uncased')\n","## return hidden layer with embeddings\n","input_ids = np.array(tokenizer.encode(txt))[None,:]  \n","embedding = nlp(input_ids)\n","embedding[0][0]"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(4, 768), dtype=float32, numpy=\n","array([[-0.34245902,  0.05200406, -0.25653803, ..., -0.24441747,\n","         0.05279738,  0.44900548],\n","       [-0.38362464, -0.6671507 , -0.3502136 , ..., -0.10210574,\n","        -0.21629463, -0.29299977],\n","       [-0.34996033, -0.08316943, -0.98768383, ...,  0.06963158,\n","        -0.49453112, -0.16088413],\n","       [ 0.7392341 ,  0.07392042, -0.45680982, ..., -0.02415731,\n","        -0.76496524, -0.28110695]], dtype=float32)>"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"jQfrqJtUrwSk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598710085577,"user_tz":-330,"elapsed":2835,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["def getSegs(corpus):\n","  maxlen = 50\n","\n","  ## add special tokens\n","  maxqnans = np.int((maxlen-20)/2)\n","  corpus_tokenized = [\"[CLS] \"+\n","              \" \".join(tokenizer.tokenize(re.sub(r'[^\\w\\s]+|\\n', '', \n","              str(txt).lower().strip()))[:maxqnans])+\n","              \" [SEP] \" for txt in corpus]\n","\n","  ## generate masks\n","  masks = [[1]*len(txt.split(\" \")) + [0]*(maxlen - len(\n","            txt.split(\" \"))) for txt in corpus_tokenized]\n","      \n","  ## padding\n","  txt2seq = [txt + \" [PAD]\"*(maxlen-len(txt.split(\" \"))) if len(txt.split(\" \")) != maxlen else txt for txt in corpus_tokenized]\n","      \n","  ## generate idx\n","  idx = [tokenizer.encode(seq.split(\" \"), max_length=maxlen, truncation=True) for seq in txt2seq]\n","\n","\n","  ## generate segments\n","  segments = [] \n","  for seq in txt2seq:\n","      temp, i = [], 0\n","      for token in seq.split(\" \"):\n","          temp.append(i)\n","          if token == \"[SEP]\":\n","              i += 1\n","      segments.append(temp)\n","  \n","  return idx, masks, segments"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MmszSXKeDa5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598710092066,"user_tz":-330,"elapsed":3168,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Separate train and target columns\n","\n","X = dfn.drop(['Assignment group', 'AG'], axis=1)\n","y = dfn['Assignment group']"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKSZCZ9Fe2vf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598710103902,"user_tz":-330,"elapsed":9735,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Split the data into train and test\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"8z52l20Ijppd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598710135327,"user_tz":-330,"elapsed":29155,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Lets create feature matrix for training set\n","\n","corpus = X_train[\"lemmatized\"]\n","\n","idx, masks, segments = getSegs(corpus)\n","\n","## feature matrix\n","X_train_m = [np.asarray(idx, dtype='int32'), \n","           np.asarray(masks, dtype='int32'), \n","           np.asarray(segments, dtype='int32')]\n"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7E94JwtgedI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1598709433407,"user_tz":-330,"elapsed":1119,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"673fd185-744c-4a72-f626-a62f90fcff87"},"source":["dfn.head()"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Short description</th>\n","      <th>Description</th>\n","      <th>Caller</th>\n","      <th>Assignment group</th>\n","      <th>AG</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>login issue</td>\n","      <td>-verified user details.(employee# &amp; manager na...</td>\n","      <td>spxjnwir pjlcoqds</td>\n","      <td>GRP_0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>outlook</td>\n","      <td>\\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...</td>\n","      <td>hmjdrvpb komuaywn</td>\n","      <td>GRP_0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cant log in to vpn</td>\n","      <td>\\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...</td>\n","      <td>eylqgodm ybqkwiam</td>\n","      <td>GRP_0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>unable to access hr_tool page</td>\n","      <td>unable to access hr_tool page</td>\n","      <td>xbkucsvz gcpydteq</td>\n","      <td>GRP_0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>skype error</td>\n","      <td>skype error</td>\n","      <td>owlgqjme qhcozdfx</td>\n","      <td>GRP_0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Short description  ... AG\n","0                    login issue  ...  0\n","1                        outlook  ...  0\n","2             cant log in to vpn  ...  0\n","3  unable to access hr_tool page  ...  0\n","4                   skype error   ...  0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"PUMjQsSgsmZA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598710164168,"user_tz":-330,"elapsed":7497,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Do the same for test data\n","\n","corpus = X_test[\"lemmatized\"]\n","\n","idx, masks, segments = getSegs(corpus)\n","  \n","## feature matrix\n","X_test_m = [np.asarray(idx, dtype='int32'), \n","           np.asarray(masks, dtype='int32'), \n","           np.asarray(segments, dtype='int32')]\n"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-oVhzCttuuQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":552},"executionInfo":{"status":"ok","timestamp":1598710200705,"user_tz":-330,"elapsed":5462,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"acd2d3cd-b1db-45e2-da5b-ee800f174f54"},"source":["#Build the model\n","\n","from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling1D\n","from tensorflow.keras.models import Model\n","\n","## inputs\n","idx = Input((50), dtype=\"int32\", name=\"input_idx\")\n","masks = Input((50), dtype=\"int32\", name=\"input_masks\")\n","segments = Input((50), dtype=\"int32\", name=\"input_segments\")\n","\n","## pre-trained bert\n","nlp = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n","bert_out, _ = nlp([idx, masks, segments])\n","\n","## fine-tuning\n","x = GlobalAveragePooling1D()(bert_out)\n","x = Dense(64, activation=\"relu\")(x)\n","y_out = Dense(len(np.unique(y_train)), activation='softmax')(x)\n","\n","## compile\n","bmodel = Model([idx, masks, segments], y_out)\n","\n","for layer in bmodel.layers[:4]:\n","    layer.trainable = False\n","\n","bmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","bmodel.summary()"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"functional_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_idx (InputLayer)          [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","input_masks (InputLayer)        [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","input_segments (InputLayer)     [(None, 50)]         0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model_2 (TFBertModel)   ((None, 50, 768), (N 109482240   input_idx[0][0]                  \n","                                                                 input_masks[0][0]                \n","                                                                 input_segments[0][0]             \n","__________________________________________________________________________________________________\n","global_average_pooling1d_1 (Glo (None, 768)          0           tf_bert_model_2[0][0]            \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 64)           49216       global_average_pooling1d_1[0][0] \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 74)           4810        dense_4[0][0]                    \n","==================================================================================================\n","Total params: 109,536,266\n","Trainable params: 54,026\n","Non-trainable params: 109,482,240\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d5xCioplEhO1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598722910811,"user_tz":-330,"elapsed":12691107,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"ea7f1cdb-1562-4575-afc3-9b1854776fd4"},"source":["#Lets train, test and evaluate\n","\n","## encode y\n","dic_y_mapping = {n:label for n,label in \n","                 enumerate(np.unique(y_train))}\n","inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n","y_train = np.array([inverse_dic[y] for y in y_train])\n","\n","\n","## train\n","training = bmodel.fit(x=X_train_m, y=y_train, batch_size=64, \n","                     epochs=50, shuffle=True, verbose=1, \n","                     validation_split=0.3)\n","\n","## test\n","predicted_prob = bmodel.predict(X_test_m)\n","predicted = [dic_y_mapping[np.argmax(pred)] for pred in \n","             predicted_prob]"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","465/465 [==============================] - 255s 549ms/step - loss: 2.6818 - accuracy: 0.3115 - val_loss: 2.3371 - val_accuracy: 0.3612\n","Epoch 2/50\n","465/465 [==============================] - 252s 542ms/step - loss: 2.2580 - accuracy: 0.3829 - val_loss: 2.1374 - val_accuracy: 0.3994\n","Epoch 3/50\n","465/465 [==============================] - 252s 542ms/step - loss: 2.0999 - accuracy: 0.4132 - val_loss: 2.0026 - val_accuracy: 0.4308\n","Epoch 4/50\n","465/465 [==============================] - 252s 541ms/step - loss: 1.9869 - accuracy: 0.4353 - val_loss: 1.9276 - val_accuracy: 0.4411\n","Epoch 5/50\n","465/465 [==============================] - 252s 541ms/step - loss: 1.9024 - accuracy: 0.4572 - val_loss: 1.8391 - val_accuracy: 0.4697\n","Epoch 6/50\n","465/465 [==============================] - 252s 541ms/step - loss: 1.8249 - accuracy: 0.4744 - val_loss: 1.7936 - val_accuracy: 0.4819\n","Epoch 7/50\n","465/465 [==============================] - 252s 541ms/step - loss: 1.7660 - accuracy: 0.4846 - val_loss: 1.7440 - val_accuracy: 0.4913\n","Epoch 8/50\n","465/465 [==============================] - 252s 541ms/step - loss: 1.7069 - accuracy: 0.5017 - val_loss: 1.6962 - val_accuracy: 0.5021\n","Epoch 9/50\n","465/465 [==============================] - 252s 541ms/step - loss: 1.6608 - accuracy: 0.5105 - val_loss: 1.6384 - val_accuracy: 0.5234\n","Epoch 10/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.6233 - accuracy: 0.5180 - val_loss: 1.5897 - val_accuracy: 0.5319\n","Epoch 11/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.5792 - accuracy: 0.5346 - val_loss: 1.5607 - val_accuracy: 0.5391\n","Epoch 12/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.5492 - accuracy: 0.5400 - val_loss: 1.5219 - val_accuracy: 0.5513\n","Epoch 13/50\n","465/465 [==============================] - 252s 543ms/step - loss: 1.5174 - accuracy: 0.5511 - val_loss: 1.5047 - val_accuracy: 0.5557\n","Epoch 14/50\n","465/465 [==============================] - 252s 543ms/step - loss: 1.4825 - accuracy: 0.5566 - val_loss: 1.4784 - val_accuracy: 0.5598\n","Epoch 15/50\n","465/465 [==============================] - 252s 543ms/step - loss: 1.4538 - accuracy: 0.5607 - val_loss: 1.4434 - val_accuracy: 0.5721\n","Epoch 16/50\n","465/465 [==============================] - 252s 543ms/step - loss: 1.4314 - accuracy: 0.5683 - val_loss: 1.4051 - val_accuracy: 0.5835\n","Epoch 17/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.4048 - accuracy: 0.5765 - val_loss: 1.4046 - val_accuracy: 0.5876\n","Epoch 18/50\n","465/465 [==============================] - 252s 543ms/step - loss: 1.3912 - accuracy: 0.5782 - val_loss: 1.3700 - val_accuracy: 0.5947\n","Epoch 19/50\n","465/465 [==============================] - 253s 543ms/step - loss: 1.3590 - accuracy: 0.5907 - val_loss: 1.3534 - val_accuracy: 0.6001\n","Epoch 20/50\n","465/465 [==============================] - 253s 543ms/step - loss: 1.3435 - accuracy: 0.5938 - val_loss: 1.3180 - val_accuracy: 0.6068\n","Epoch 21/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.3264 - accuracy: 0.5968 - val_loss: 1.3206 - val_accuracy: 0.6058\n","Epoch 22/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.3100 - accuracy: 0.5991 - val_loss: 1.3040 - val_accuracy: 0.6111\n","Epoch 23/50\n","465/465 [==============================] - 252s 543ms/step - loss: 1.2905 - accuracy: 0.6075 - val_loss: 1.2779 - val_accuracy: 0.6215\n","Epoch 24/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.2749 - accuracy: 0.6080 - val_loss: 1.2665 - val_accuracy: 0.6194\n","Epoch 25/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.2589 - accuracy: 0.6170 - val_loss: 1.2524 - val_accuracy: 0.6261\n","Epoch 26/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.2492 - accuracy: 0.6208 - val_loss: 1.2398 - val_accuracy: 0.6324\n","Epoch 27/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.2355 - accuracy: 0.6201 - val_loss: 1.2104 - val_accuracy: 0.6398\n","Epoch 28/50\n","465/465 [==============================] - 252s 543ms/step - loss: 1.2210 - accuracy: 0.6252 - val_loss: 1.2067 - val_accuracy: 0.6417\n","Epoch 29/50\n","465/465 [==============================] - 252s 543ms/step - loss: 1.2154 - accuracy: 0.6259 - val_loss: 1.1990 - val_accuracy: 0.6383\n","Epoch 30/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.2004 - accuracy: 0.6316 - val_loss: 1.1985 - val_accuracy: 0.6388\n","Epoch 31/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1902 - accuracy: 0.6338 - val_loss: 1.1891 - val_accuracy: 0.6481\n","Epoch 32/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1817 - accuracy: 0.6339 - val_loss: 1.1697 - val_accuracy: 0.6527\n","Epoch 33/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1743 - accuracy: 0.6358 - val_loss: 1.1558 - val_accuracy: 0.6594\n","Epoch 34/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1695 - accuracy: 0.6397 - val_loss: 1.1578 - val_accuracy: 0.6529\n","Epoch 35/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1592 - accuracy: 0.6402 - val_loss: 1.1442 - val_accuracy: 0.6592\n","Epoch 36/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1506 - accuracy: 0.6427 - val_loss: 1.1361 - val_accuracy: 0.6624\n","Epoch 37/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1399 - accuracy: 0.6462 - val_loss: 1.1293 - val_accuracy: 0.6606\n","Epoch 38/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1338 - accuracy: 0.6461 - val_loss: 1.1431 - val_accuracy: 0.6569\n","Epoch 39/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1264 - accuracy: 0.6500 - val_loss: 1.1177 - val_accuracy: 0.6618\n","Epoch 40/50\n","465/465 [==============================] - 252s 542ms/step - loss: 1.1192 - accuracy: 0.6507 - val_loss: 1.1034 - val_accuracy: 0.6694\n","Epoch 41/50\n","465/465 [==============================] - 251s 541ms/step - loss: 1.1083 - accuracy: 0.6522 - val_loss: 1.1089 - val_accuracy: 0.6674\n","Epoch 42/50\n","465/465 [==============================] - 250s 537ms/step - loss: 1.1003 - accuracy: 0.6555 - val_loss: 1.0924 - val_accuracy: 0.6715\n","Epoch 43/50\n","465/465 [==============================] - 250s 537ms/step - loss: 1.1009 - accuracy: 0.6576 - val_loss: 1.0970 - val_accuracy: 0.6715\n","Epoch 44/50\n","465/465 [==============================] - 250s 538ms/step - loss: 1.0939 - accuracy: 0.6571 - val_loss: 1.0951 - val_accuracy: 0.6698\n","Epoch 45/50\n","465/465 [==============================] - 250s 538ms/step - loss: 1.0848 - accuracy: 0.6604 - val_loss: 1.0768 - val_accuracy: 0.6776\n","Epoch 46/50\n","465/465 [==============================] - 250s 538ms/step - loss: 1.0738 - accuracy: 0.6616 - val_loss: 1.0901 - val_accuracy: 0.6720\n","Epoch 47/50\n","465/465 [==============================] - 251s 539ms/step - loss: 1.0722 - accuracy: 0.6624 - val_loss: 1.0819 - val_accuracy: 0.6727\n","Epoch 48/50\n","465/465 [==============================] - 250s 539ms/step - loss: 1.0695 - accuracy: 0.6659 - val_loss: 1.0841 - val_accuracy: 0.6709\n","Epoch 49/50\n","465/465 [==============================] - 250s 538ms/step - loss: 1.0695 - accuracy: 0.6640 - val_loss: 1.0737 - val_accuracy: 0.6808\n","Epoch 50/50\n","465/465 [==============================] - 250s 538ms/step - loss: 1.0582 - accuracy: 0.6687 - val_loss: 1.0625 - val_accuracy: 0.6830\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Lfqed26mjkyw","colab_type":"text"},"source":["# Lets try XLNet now"]},{"cell_type":"code","metadata":{"id":"3d0wd1cugRPU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1598722995158,"user_tz":-330,"elapsed":4391,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"f9af8ce3-5fe9-4c19-8147-b7d2b9207245"},"source":["!pip install pytorch-transformers"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.6.0+cu101)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.23.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.91)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.43)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.14.48)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.16.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.10.0)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n","Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.17.48)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch-transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch-transformers) (2.8.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5CrOrNVwgq7Z","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723009134,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","from transformers import TFXLNetForSequenceClassification, XLNetForSequenceClassification\n","from pytorch_transformers import XLNetModel, XLNetTokenizer\n","from pytorch_transformers import AdamW\n","\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","% matplotlib inline"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"zYcVNeydg1FE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598723018301,"user_tz":-330,"elapsed":1263,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"081ef1cc-30cf-4c8c-fe4e-2ab531412473"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla K80'"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"RfleHlT8g9Z-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723022389,"user_tz":-330,"elapsed":1628,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["sentences = dfn.lemmatized.values"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"u6Mxd1MUhVYM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723025030,"user_tz":-330,"elapsed":1273,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["sentences = [sentence + \" [SEP] [CLS]\" for sentence in sentences]"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rO2UX90r3_c","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723028234,"user_tz":-330,"elapsed":1199,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#no of groups\n","groups = dfn.AG.nunique()"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLrM-6IKhjHU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598723032945,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"52992c7b-6768-4872-8156-47b03122b072"},"source":["sentences[0]"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'user details employee manager name user name ad reset user login confirm able resolve [SEP] [CLS]'"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"9X2HJR4ZhqkB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598723049123,"user_tz":-330,"elapsed":10308,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"29a294dc-95a4-4184-dc4c-b38ac56d20e7"},"source":["tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n","\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","print (\"Tokenize the first sentence:\")\n","print (tokenized_texts[0])"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Tokenize the first sentence:\n","['▁user', '▁details', '▁employee', '▁manager', '▁name', '▁user', '▁name', '▁a', 'd', '▁reset', '▁user', '▁login', '▁confirm', '▁able', '▁resolve', '▁[', 's', 'ep', ']', '▁[', 'cl', 's', ']']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"voo2N5b3hxVm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723054456,"user_tz":-330,"elapsed":1409,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["MAX_LEN = 128"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKwxXhrfh0HP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723060325,"user_tz":-330,"elapsed":3399,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAat1U-Mh4kn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723066533,"user_tz":-330,"elapsed":1592,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"A715wBkCh9Ey","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723077860,"user_tz":-330,"elapsed":5965,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["# Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"PAre1QqmiDpu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723083018,"user_tz":-330,"elapsed":1756,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["#Use train_test_split to split our data into train and validation sets for training\n","\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","                                                            random_state=56, test_size=0.2)\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                             random_state=56, test_size=0.2)"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"Avv2oY7PiH_F","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723092745,"user_tz":-330,"elapsed":1593,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["# Convert all of our data into torch tensors, the required datatype for our model\n","\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"WhI3Lh_2iOFj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723097149,"user_tz":-330,"elapsed":1253,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n","batch_size = 32\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"3f455YWGrGm8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1598723152147,"user_tz":-330,"elapsed":6070,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"db183ff0-d278-4d0d-9edf-5c2fab2b9896"},"source":["# Load XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top. \n","\n","xlmodel = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=groups)"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.weight', 'logits_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KUJv_9kNBJ22","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598723187691,"user_tz":-330,"elapsed":1143,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"a9d492cd-7f62-4a72-e180-a0c7e82fe96d"},"source":["xlmodel.cuda()"],"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLNetForSequenceClassification(\n","  (transformer): XLNetModel(\n","    (word_embedding): Embedding(32000, 768)\n","    (layer): ModuleList(\n","      (0): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (6): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (7): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (8): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (9): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (10): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (11): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (sequence_summary): SequenceSummary(\n","    (summary): Linear(in_features=768, out_features=768, bias=True)\n","    (first_dropout): Identity()\n","    (last_dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (logits_proj): Linear(in_features=768, out_features=74, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"id":"o7difDwJuRaE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723209470,"user_tz":-330,"elapsed":1242,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["param_optimizer = list(xlmodel.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_HCa0amC4QE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723213596,"user_tz":-330,"elapsed":1321,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["# This variable contains all of the hyperparemeter information our training loop needs\n","optimizer = AdamW(optimizer_grouped_parameters,\n","                     lr=2e-5)"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHlfi9fkC-bT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1598617773273,"user_tz":-330,"elapsed":9390742,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"4e67375f-411c-4bec-b485-313077ddd285"},"source":["train_loss_set = []\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 4\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","  \n","  \n","  # Training\n","  \n","  # Set our model to training mode (as opposed to evaluation mode)\n","  xlmodel.train()\n","  # Tracking variables\n","  tr_loss = 0\n","  nb_tr_examples, nb_tr_steps = 0, 0\n","  \n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","    # Forward pass\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","    loss = outputs[0]\n","    logits = outputs[1]\n","    train_loss_set.append(loss.item())\n","    # Backward pass\n","    loss.backward()\n","    # Update parameters and take a step using the computed gradient\n","    optimizer.step()\n","    \n","    # Update tracking variables\n","    tr_loss += loss.item()\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","\n","  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:  25%|██▌       | 1/4 [39:11<1:57:33, 2351.16s/it]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.6643551520009461\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  50%|█████     | 2/4 [1:18:21<1:18:22, 2351.06s/it]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.502620519757181\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch:  75%|███████▌  | 3/4 [1:57:25<39:08, 2348.85s/it]  "],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.45667686182008976\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch: 100%|██████████| 4/4 [2:36:29<00:00, 2347.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["Train loss: 0.42826638063352723\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QGm-7LKDcJ5L","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598723277999,"user_tz":-330,"elapsed":1642,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}}},"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"3HKDXodR824H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598618753413,"user_tz":-330,"elapsed":237126,"user":{"displayName":"Atul Kumar","photoUrl":"","userId":"02267315536838712153"}},"outputId":"73af11a8-8a31-4e97-cc64-b52761da2cdd"},"source":["# Validation\n","\n","# Put model in evaluation mode to evaluate loss on the validation set\n","xlmodel.eval()\n","\n","# Tracking variables \n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# Evaluate data for one epoch\n","for batch in validation_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    output = xlmodel(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    logits = output[0]\n","  \n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","  tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","  \n","  eval_accuracy += tmp_eval_accuracy\n","  nb_eval_steps += 1\n","\n","print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Validation Accuracy: 0.8608078145917002\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z7Vb5T0PcLQV","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/NLP/model_without_language_model1.ckpt')"],"execution_count":null,"outputs":[]}]}